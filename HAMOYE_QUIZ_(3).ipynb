{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '~/Downloads/Data_for_UCI_named.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1     9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2     8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3     0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4     3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "0    -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1    -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2    -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3    -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4    -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  0.023892  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120 -0.025803    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984 -0.031810    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  0.037789  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  0.045263  unstable  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['stab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['stabf'])\n",
    "Y = df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the dataset using standard scaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_df = scaler.fit_transform(x_train)\n",
    "x_train_df = pd.DataFrame(x_train_df, columns=x_train.columns)\n",
    "\n",
    "#y_train_df = scaler.fit_transform(y_train)\n",
    "#y_train_df = pd.DataFrame(y_train_df)\n",
    "\n",
    "x_test_df = scaler.fit_transform(x_test)\n",
    "x_test_df = pd.DataFrame(x_test_df, columns=x_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uthmani/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/uthmani/.local/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:51:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.946"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "# define dataset\n",
    "# define the model\n",
    "XG_model = XGBClassifier(random_state=1)\n",
    "XG_model = XG_model.fit(x_train_df, y_train)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred = XG_model.predict(x_test_df))\n",
    "print('Accuracy: {}'.format(round(accuracy, 4))) #\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9365\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "# define dataset\n",
    "# define the model\n",
    "LG_model = LGBMClassifier(random_state=1)\n",
    "# fit the model on the whole dataset\n",
    "LG_model = LG_model.fit(x_train_df, y_train)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred = LG_model.predict(x_test_df))\n",
    "print('Accuracy: {}'.format(round((accuracy),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#from sklearn.datasets import make_classification\n",
    "#X, y = make_classification(n_features=4, random_state=0)\n",
    "XTmodel = ExtraTreesClassifier(random_state = 1)\n",
    "model_params = {\n",
    "    # list of n_estimators to select from\n",
    "    'n_estimators': [100, 300, 500, 1000],\n",
    "    # min_samples_leaf list to select from\n",
    "    'min_samples_leaf': [6, 8, 4],\n",
    "    # list of min_sample_split and max_features to select from based on the question \n",
    "    'min_samples_split': [2,5,7],\n",
    "    \n",
    "    'max_features': ['auto', None, 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "RSV = RandomizedSearchCV(XTmodel, model_params, cv=5, n_iter=10, scoring='accuracy', n_jobs=-1, verbose=1,random_state=1)\n",
    "search = RSV.fit(x_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 5,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Hyperparameters according to the randomized search CV\n",
    "\n",
    "search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal ExtraTreesClassifier\n",
    "OXTmodel = ExtraTreesClassifier(random_state = 1, bootstrap= False,\n",
    "                                 ccp_alpha = 0.0,\n",
    "                                 class_weight= None,\n",
    "                                 criterion= 'gini',\n",
    "                                 max_depth= None,\n",
    "                                 max_features= None,\n",
    "                                 max_leaf_nodes= None,\n",
    "                                 max_samples= None,\n",
    "                                 min_impurity_decrease= 0.0,\n",
    "                                 min_samples_leaf= 4,\n",
    "                                 min_samples_split= 5,\n",
    "                                 min_weight_fraction_leaf= 0.0,\n",
    "                                 n_estimators= 500,\n",
    "                                 n_jobs= None,\n",
    "                                 oob_score= False,\n",
    "                                 verbose= 0,\n",
    "                                 warm_start= False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935\n"
     ]
    }
   ],
   "source": [
    "# optimal ExtraTreesClassifier accuracy score\n",
    "\n",
    "OXTmodel = OXTmodel.fit(x_train_df, y_train)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred = OXTmodel.predict(x_test_df))\n",
    "print('Accuracy: {}'.format(round((accuracy),4)))\n",
    "\n",
    "# I tried calculating the accuracies for all the options in the question but none gives a better accuracy score as the Hyperparameter combination I got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.926\n"
     ]
    }
   ],
   "source": [
    "# initial ExtraTreesClassifier accuracy score without hyperparameter tuning\n",
    "\n",
    "XTmodel = XTmodel.fit(x_train_df, y_train)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred = XTmodel.predict(x_test_df))\n",
    "print('Accuracy: {}'.format(round((accuracy),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13312272 0.13505643 0.13015047 0.13023924 0.0082835  0.01087562\n",
      " 0.0109557  0.01028787 0.10299321 0.10780024 0.11179932 0.10843569]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most important features using the optimal ExtraTreesClassifier model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(OXTmodel.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(OXTmodel.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(12).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "# from the graph below tau2 is the most important feature and p1 is the least important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "#Random forest classifier \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFCmodel = RandomForestClassifier(random_state=1)\n",
    "RFCmodel = RFCmodel.fit(x_train_df, y_train)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred = RFCmodel.predict(x_test_df))\n",
    "print('Accuracy: {}'.format(round(accuracy,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
